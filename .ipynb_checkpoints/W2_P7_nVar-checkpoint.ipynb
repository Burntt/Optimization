{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 457,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from math import sqrt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 458,
   "metadata": {},
   "outputs": [],
   "source": [
    "def L2norm(vector):\n",
    "    sumsquares = np.sum(np.power(vector,2))\n",
    "    return sumsquares**(0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 459,
   "metadata": {},
   "outputs": [],
   "source": [
    "def norm(x):\n",
    "    return sqrt(sum(t**2 for t in x))\n",
    "\n",
    "def sqrnorm(x):\n",
    "    return sum(t**2 for t in x)\n",
    "\n",
    "def L2norm(vector):\n",
    "    sumsquares = np.sum(np.power(vector,2))\n",
    "    return sumsquares**(0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 460,
   "metadata": {},
   "outputs": [],
   "source": [
    "def approximate_gradient(f, x, n, gamma, valf=None):\n",
    "    if valf is None:\n",
    "        valf = f(x)\n",
    "    grad_approx = np.array([-valf]*n)\n",
    "    for j in range(n):\n",
    "        grad_approx[j] += f(x[:j] + [x[j]+gamma] + x[j+1:])\n",
    "        grad_approx[j] /= gamma\n",
    "    return (np.array(grad_approx), valf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 461,
   "metadata": {},
   "outputs": [],
   "source": [
    "def armijo(f, grad_approx, x, c, alpha, stepdir):\n",
    "    return (\n",
    "        f(np.array(x - alpha*stepdir)) < f(x) - c * alpha*( np.dot(stepdir, grad_approx) )\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 462,
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimizer(f, initial, tolerance, max_iter, c, c1 ,c2):\n",
    "    x_current = initial\n",
    "    n = len(initial)\n",
    "    acc_x = np.array([0]*len(initial))\n",
    "    \n",
    "    iteration = 0\n",
    "    \n",
    "    for i in range(max_iter):\n",
    "        \n",
    "        gamma = tol/(i+1)\n",
    "        \n",
    "        grad_approx, valf = approximate_gradient(\n",
    "            f, \n",
    "            x_current, \n",
    "            n,\n",
    "            gamma\n",
    "        )\n",
    "        \n",
    "        alpha = 1.\n",
    "        \n",
    "        stepdir = c1*acc_x + c2*grad_approx\n",
    "        \n",
    "        while armijo(f, grad_approx, x_current, c, alpha * 1.5, stepdir):\n",
    "            alpha *= 1.5\n",
    "        max_iter_armijo = 100\n",
    "        cur_iter_armijo = 0\n",
    "        while not armijo(f, grad_approx, x_current, c, alpha, stepdir):\n",
    "            alpha *= 0.5        \n",
    "            cur_iter_armijo += 1\n",
    "            if cur_iter_armijo > max_iter_armijo:\n",
    "                return x_current\n",
    "              \n",
    "        x_next = list(x_current - alpha * stepdir)\n",
    "        x_current = x_next   \n",
    "        \n",
    "        acc_x = stepdir\n",
    "        iteration = iteration + 1\n",
    "        \n",
    "    return list(x_current)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Enter sample input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 463,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f(x): \n",
    "    n = len(x)\n",
    "    p = 1\n",
    "    q = 10\n",
    "    t = sum((p-x[2*i])**2+q*(x[2*i+1]-x[2*i]**2)**2 for i in range(n//2))\n",
    "    return t if n % 2 == 0 else (t + x[n-1]**2)\n",
    "tol = 0.00001\n",
    "initial = (0.,) * 40"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 464,
   "metadata": {},
   "outputs": [],
   "source": [
    "initial = list(initial)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optimization for hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 466,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best hyperparameters || c , c1 , c2 =  [0.1, 0.2, 0.1]\n"
     ]
    }
   ],
   "source": [
    "# # Required final coordinates\n",
    "# single_coord = 3.99999\n",
    "# final_coord_vec =  len(initial)*[single_coord]\n",
    "\n",
    "# #Other settings for hyperparameter optimization\n",
    "# div = 10\n",
    "# iter_max = 100\n",
    "\n",
    "# from itertools import product\n",
    "\n",
    "# c = np.linspace(0, 1, div, endpoint=False)[1:]\n",
    "# c1 = np.linspace(0, 1, div, endpoint=False)[1:]\n",
    "# c2 = np.linspace(0, 1, div, endpoint=False)[1:]\n",
    "\n",
    "# n_ele = len(c)*len(c1)*len(c2)\n",
    "# vec_hyperpara = []\n",
    "# for c, c1, c2 in product(c, c1, c2):\n",
    "#     vec_hyperpara.append([c, c1, c2])\n",
    "    \n",
    "# list_of_error = []\n",
    "# list_of_norm = []\n",
    "# for p in range(n_ele):\n",
    "#     c_init, c1_init, c2_init = vec_hyperpara[p]  \n",
    "#     sol = optimizer(f, initial, tol, max_iter = iter_max, c = c_init, c1 = c1_init, c2 = c2_init)\n",
    "#     list_of_error.append( list(np.array(sol) - final_coord_vec) )\n",
    "#     list_of_norm.append( L2norm(list_of_error[p]) )\n",
    "# minpos = norm_list.index(min(norm_list))\n",
    "# best_hyperpara = vec_hyperpara[minpos]\n",
    "\n",
    "# print('best hyperparameters || c , c1 , c2 = ', best_hyperpara)\n",
    "\n",
    "# c , c1 , c2 = best_hyperpara\n",
    "\n",
    "\n",
    "# # problem 1 best: c , c1 , c2 =  [0.1, 0.2, 0.1]\n",
    "# # problem 2 best: c , c1 , c2 =  [0.1, 0.2, 0.1]\n",
    "\n",
    "c , c1 , c2 =  [0.1, 0.2, 0.1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Print final solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 469,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.99999996117333, 0.9999999209742142, 0.99999996117333, 0.9999999209742142, 0.9999999611733196, 0.9999999209742164, 0.9999999611733299, 0.9999999209742151, 0.9999999611733291, 0.9999999209742151, 0.9999999611733299, 0.9999999209742151, 0.9999999611733291, 0.9999999209742151, 0.9999999611733299, 0.9999999209742151, 0.9999999611733299, 0.9999999209742151, 0.99999996117333, 0.9999999209742142, 0.99999996117333, 0.9999999209742142, 0.9999999611733299, 0.9999999209742151, 0.9999999611733299, 0.9999999209742151, 0.9999999611733299, 0.9999999209742151, 0.9999999611733299, 0.9999999209742151, 0.9999999611733299, 0.9999999209742151, 0.9999999611733291, 0.9999999209742151, 0.9999999611733299, 0.9999999209742151, 0.9999999611733291, 0.9999999209742151, 0.9999999611733299, 0.9999999209742151]\n"
     ]
    }
   ],
   "source": [
    "initial = list(initial)\n",
    "sol = optimizer(f, initial, tol, max_iter=10000, c = c, c1 = c1 , c2 = c2) \n",
    "print(sol)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
